{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This use to generate explanability for SM VIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install ml_collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.normalization.LayerNorm' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.activation.Softmax' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.load('models\\SMVIT.pt',map_location=torch.device('cpu'))\n",
    "# print(model.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melanoma\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from vit_pytorch import ViT\n",
    "import torch\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "\n",
    "\n",
    "from pytorch_grad_cam import GradCAM, \\\n",
    "    ScoreCAM, \\\n",
    "    GradCAMPlusPlus, \\\n",
    "    AblationCAM, \\\n",
    "    XGradCAM, \\\n",
    "    EigenCAM, \\\n",
    "    EigenGradCAM, \\\n",
    "    LayerCAM, \\\n",
    "    FullGrad\n",
    "\n",
    "from pytorch_grad_cam import GuidedBackpropReLUModel\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image,preprocess_image\n",
    "from pytorch_grad_cam.ablation_layer import AblationLayerVit\n",
    "\n",
    "\n",
    "def reshape_transform(tensor, height=14, width=14):\n",
    "    result = tensor[:, 1:, :].reshape(tensor.size(0),\n",
    "                                      height, width, tensor.size(2))\n",
    "\n",
    "    # Bring the channels to the first dimension,\n",
    "    # like in CNNs.\n",
    "    result = result.transpose(2, 3).transpose(1, 2)\n",
    "    return result\n",
    "\n",
    "\n",
    "methods = {\"gradcam\": GradCAM,\n",
    "         \"scorecam\": ScoreCAM,\n",
    "         \"gradcam++\": GradCAMPlusPlus }\n",
    "\n",
    "\n",
    "\n",
    "# target_layers = [model.transformer.encoder.layer[0].attention_norm]\n",
    "target_layers = [model.transformer.encoder.layer[1].attention_norm]\n",
    "# target_layers = [model.transformer.encoder.layer[-1].attention_norm]\n",
    "\n",
    "# method='gradcam'\n",
    "method='gradcam'\n",
    "\n",
    "cam = methods[method](model=model,target_layers=target_layers,use_cuda=False,reshape_transform=reshape_transform)\n",
    "\n",
    "url='Sample Mel and Nev\\Mel\\ISIC_0029495.JPG'\n",
    "rgb_img = cv2.imread(url, 1)[:, :, ::-1]\n",
    "rgb_img = cv2.resize(rgb_img, (224, 224))\n",
    "rgb_img = np.float32(rgb_img) / 255\n",
    "input_tensor = preprocess_image(rgb_img, mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "\n",
    "# If None, returns the map for the highest scoring category.\n",
    "# Otherwise, targets the requested category.\n",
    "targets = None\n",
    "# input_tensor = input_tensor.cuda()\n",
    "# AblationCAM and ScoreCAM have batched implementations.\n",
    "# You can override the internal batch size for faster computation.\n",
    "cam.batch_size = 32\n",
    "\n",
    "skin_class=['Melanoma','Non-Melanoma']\n",
    "outputs = cam.activations_and_grads(input_tensor)[0]\n",
    "# print(outputs[0])\n",
    "\n",
    "if targets is None:\n",
    "    target_categories = np.argmax(outputs.cpu().data.numpy(), axis=-1)\n",
    "    print(skin_class[target_categories[0]])\n",
    "    targets = [ClassifierOutputTarget(category) for category in target_categories]\n",
    "\n",
    "grayscale_cam = cam(input_tensor=input_tensor,aug_smooth =False,targets=targets)\n",
    "\n",
    "# Here grayscale_cam has only one image in the batch\n",
    "grayscale_cam = grayscale_cam[0, :]\n",
    "\n",
    "cam_image = show_cam_on_image(rgb_img, grayscale_cam)\n",
    "\n",
    "name=url.split('.')[0].split('/')[-1]\n",
    "cv2.imwrite(f''+name+\"_\"+method+'.jpg', cam_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
